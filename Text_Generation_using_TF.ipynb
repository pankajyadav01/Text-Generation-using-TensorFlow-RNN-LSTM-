{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/wittyicon29/Text-Generation-using-TensorFlow-RNN-LSTM-/blob/main/Text_Generation_using_TF.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BOwsuGQQY9OL",
        "tags": [
          "graded"
        ]
      },
      "outputs": [],
      "source": [
        "import numpy as np \n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.utils import to_categorical \n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense, Bidirectional\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WZ4qOUzujMP6",
        "tags": [
          "graded"
        ],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8a26d2b7-e85e-46a0-9b6f-413d4208f8c5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/gdown/cli.py:127: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n",
            "  warnings.warn(\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=108jAePKK4R3BVYBbYJZ32JWUwxeMg20K\n",
            "To: /content/sonnets.txt\n",
            "100% 93.6k/93.6k [00:00<00:00, 8.30MB/s]\n"
          ]
        }
      ],
      "source": [
        "# sonnets.txt\n",
        "!gdown --id 108jAePKK4R3BVYBbYJZ32JWUwxeMg20K"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pfd-nYKij5yY",
        "tags": [
          "graded"
        ],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "924f6484-df11-4a14-af56-1a7e1af19ed8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 2159 lines of sonnets\n",
            "\n",
            "The first 5 lines look like this:\n",
            "\n",
            "from fairest creatures we desire increase,\n",
            "that thereby beauty's rose might never die,\n",
            "but as the riper should by time decease,\n",
            "his tender heir might bear his memory:\n",
            "but thou, contracted to thine own bright eyes,\n"
          ]
        }
      ],
      "source": [
        "# Define path for file with sonnets\n",
        "SONNETS_FILE = './sonnets.txt'\n",
        "\n",
        "# Read the data\n",
        "with open('./sonnets.txt') as f:\n",
        "    data = f.read()\n",
        "\n",
        "# Convert to lower case and save as a list\n",
        "corpus = data.lower().split(\"\\n\")\n",
        "\n",
        "print(f\"There are {len(corpus)} lines of sonnets\\n\")\n",
        "print(f\"The first 5 lines look like this:\\n\")\n",
        "for i in range(5):\n",
        "  print(corpus[i])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AAhM_qAZk0o5",
        "tags": [
          "graded"
        ]
      },
      "outputs": [],
      "source": [
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(corpus)\n",
        "total_words = len(tokenizer.word_index) + 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tqhPxdeXlfjh",
        "tags": [
          "graded"
        ],
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "f211f229-ff18-43fd-d61d-656ec7cd2415"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'from fairest creatures we desire increase,'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "corpus[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EMSEhmbzNZCE",
        "tags": [
          "graded"
        ],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6495b6dd-60d3-425e-b47e-58029c921651"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[],\n",
              " [],\n",
              " [58],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [17],\n",
              " [6],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [17],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [6],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [6],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [17],\n",
              " [],\n",
              " [],\n",
              " []]"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "tokenizer.texts_to_sequences(corpus[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qmgo-vXhk4nd",
        "tags": [
          "graded"
        ],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "414a7756-ca1d-48a2-a79a-210519f549a0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[34, 417, 877, 166, 213, 517]]"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "tokenizer.texts_to_sequences([corpus[0]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kpTy8WmIQ57P",
        "tags": [
          "graded"
        ],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "634b8ba0-63d4-4a3a-d367-9d85710ebec7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[34, 417, 877, 166, 213, 517]"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "tokenizer.texts_to_sequences([corpus[0]])[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-oqy9KjXRJ9A"
      },
      "source": [
        "## Generating n_grams\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iy4baJMDl6kj",
        "tags": [
          "graded"
        ]
      },
      "outputs": [],
      "source": [
        "\n",
        "def n_gram_seqs(corpus, tokenizer):\n",
        "    \"\"\"\n",
        "    Generates a list of n-gram sequences\n",
        "    \n",
        "    Args:\n",
        "        corpus (list of string): lines of texts to generate n-grams for\n",
        "        tokenizer (object): an instance of the Tokenizer class containing the word-index dictionary\n",
        "    \n",
        "    Returns:\n",
        "        input_sequences (list of int): the n-gram sequences for each line in the corpus\n",
        "    \"\"\"\n",
        "    input_sequences = []\n",
        "    \n",
        "\n",
        "    for line in corpus:\n",
        "      token_list = tokenizer.texts_to_sequences([line])[0]\n",
        "      for i in range(1, len(token_list)):\n",
        "        n_gram_sequence = token_list[:i+1]\n",
        "        input_sequences.append(n_gram_sequence)\n",
        "    \n",
        "\n",
        "    \n",
        "    return input_sequences"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DlKqW2pfM7G3",
        "tags": [
          "graded"
        ],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "170ea443-f3e8-4526-9a6b-d46c97725921"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "n_gram sequences for first example look like this:\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[34, 417],\n",
              " [34, 417, 877],\n",
              " [34, 417, 877, 166],\n",
              " [34, 417, 877, 166, 213],\n",
              " [34, 417, 877, 166, 213, 517]]"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "# Test \n",
        "first_example_sequence = n_gram_seqs([corpus[0]], tokenizer)\n",
        "\n",
        "print(\"n_gram sequences for first example look like this:\\n\")\n",
        "first_example_sequence"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wtPpCcBjNc4c",
        "tags": [
          "graded"
        ],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ea442fc0-c7f2-4d75-85c8-05494d59db2d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "n_gram sequences for next 3 examples look like this:\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[8, 878],\n",
              " [8, 878, 134],\n",
              " [8, 878, 134, 351],\n",
              " [8, 878, 134, 351, 102],\n",
              " [8, 878, 134, 351, 102, 156],\n",
              " [8, 878, 134, 351, 102, 156, 199],\n",
              " [16, 22],\n",
              " [16, 22, 2],\n",
              " [16, 22, 2, 879],\n",
              " [16, 22, 2, 879, 61],\n",
              " [16, 22, 2, 879, 61, 30],\n",
              " [16, 22, 2, 879, 61, 30, 48],\n",
              " [16, 22, 2, 879, 61, 30, 48, 634],\n",
              " [25, 311],\n",
              " [25, 311, 635],\n",
              " [25, 311, 635, 102],\n",
              " [25, 311, 635, 102, 200],\n",
              " [25, 311, 635, 102, 200, 25],\n",
              " [25, 311, 635, 102, 200, 25, 278]]"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "# Test \n",
        "next_3_examples_sequence = n_gram_seqs(corpus[1:4], tokenizer)\n",
        "\n",
        "print(\"n_gram sequences for next 3 examples look like this:\\n\")\n",
        "next_3_examples_sequence"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dx3V_RjFWQSu"
      },
      "source": [
        "Apply the `n_gram_seqs` transformation to the whole corpus and save the maximum sequence length to use it later:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "laMwiRUpmuSd",
        "tags": [
          "graded"
        ],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4a2f1c7e-d4b2-4edd-810a-5f909aee9542"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "n_grams of input_sequences have length: 15462\n",
            "maximum length of sequences is: 11\n"
          ]
        }
      ],
      "source": [
        "#Apply the n_gram_seqs transformation to the whole corpus\n",
        "input_sequences = n_gram_seqs(corpus, tokenizer)\n",
        "\n",
        "# Save max length \n",
        "max_sequence_len = max([len(x) for x in input_sequences])\n",
        "\n",
        "print(f\"n_grams of input_sequences have length: {len(input_sequences)}\")\n",
        "print(f\"maximum length of sequences is: {max_sequence_len}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zHY7HroqWq12"
      },
      "source": [
        "## Add padding to the sequences\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "code",
        "id": "WW1-qAZaWOhC",
        "tags": [
          "graded"
        ]
      },
      "outputs": [],
      "source": [
        "\n",
        "def pad_seqs(input_sequences, maxlen):\n",
        "    \"\"\"\n",
        "    Pads tokenized sequences to the same length\n",
        "    \n",
        "    Args:\n",
        "        input_sequences (list of int): tokenized sequences to pad\n",
        "        maxlen (int): maximum length of the token sequences\n",
        "    \n",
        "    Returns:\n",
        "        padded_sequences (array of int): tokenized sequences padded to the same length\n",
        "    \"\"\"\n",
        "\n",
        "    padded_sequences = np.array(pad_sequences(input_sequences, maxlen=max_sequence_len, padding='pre'))\n",
        "    \n",
        "    return padded_sequences\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IqVQ0pb3YHLr",
        "tags": [
          "graded"
        ],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2754d1cd-98cc-476d-b95a-5219346a2c7e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[  0,   0,   0,   0,   0,   0,   0,   0,   0,  34, 417],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,  34, 417, 877],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,  34, 417, 877, 166],\n",
              "       [  0,   0,   0,   0,   0,   0,  34, 417, 877, 166, 213],\n",
              "       [  0,   0,   0,   0,   0,  34, 417, 877, 166, 213, 517]],\n",
              "      dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "# Test your function with the n_grams_seq of the first example\n",
        "first_padded_seq = pad_seqs(first_example_sequence, max([len(x) for x in first_example_sequence]))\n",
        "first_padded_seq"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j56_UCOBYzZt",
        "tags": [
          "graded"
        ],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "694285ce-29c6-47d3-9860-83719e1dbacd"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[  0,   0,   0,   0,   0,   0,   0,   0,   0,   8, 878],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   8, 878, 134],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   8, 878, 134, 351],\n",
              "       [  0,   0,   0,   0,   0,   0,   8, 878, 134, 351, 102],\n",
              "       [  0,   0,   0,   0,   0,   8, 878, 134, 351, 102, 156],\n",
              "       [  0,   0,   0,   0,   8, 878, 134, 351, 102, 156, 199],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,  16,  22],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,  16,  22,   2],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,  16,  22,   2, 879],\n",
              "       [  0,   0,   0,   0,   0,   0,  16,  22,   2, 879,  61],\n",
              "       [  0,   0,   0,   0,   0,  16,  22,   2, 879,  61,  30],\n",
              "       [  0,   0,   0,   0,  16,  22,   2, 879,  61,  30,  48],\n",
              "       [  0,   0,   0,  16,  22,   2, 879,  61,  30,  48, 634],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,  25, 311],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,  25, 311, 635],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,  25, 311, 635, 102],\n",
              "       [  0,   0,   0,   0,   0,   0,  25, 311, 635, 102, 200],\n",
              "       [  0,   0,   0,   0,   0,  25, 311, 635, 102, 200,  25],\n",
              "       [  0,   0,   0,   0,  25, 311, 635, 102, 200,  25, 278]],\n",
              "      dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "# Test your function with the n_grams_seq of the next 3 examples\n",
        "next_3_padded_seq = pad_seqs(next_3_examples_sequence, max([len(s) for s in next_3_examples_sequence]))\n",
        "next_3_padded_seq"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rgK-Q_micEYA",
        "tags": [
          "graded"
        ],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9bf831d4-683f-44c6-e409-7f46d93f4036"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "padded corpus has shape: (15462, 11)\n"
          ]
        }
      ],
      "source": [
        "# Pad the whole corpus\n",
        "input_sequences = pad_seqs(input_sequences, max_sequence_len)\n",
        "\n",
        "print(f\"padded corpus has shape: {input_sequences.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZbOidyPrXxf7"
      },
      "source": [
        "## Split the data into features and labels\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "code",
        "id": "9WGGbYdnZdmJ",
        "tags": [
          "graded"
        ]
      },
      "outputs": [],
      "source": [
        "\n",
        "def features_and_labels(input_sequences, total_words):\n",
        "    \"\"\"\n",
        "    Generates features and labels from n-grams\n",
        "    \n",
        "    Args:\n",
        "        input_sequences (list of int): sequences to split features and labels from\n",
        "        total_words (int): vocabulary size\n",
        "    \n",
        "    Returns:\n",
        "        features, one_hot_labels (array of int, array of int): arrays of features and one-hot encoded labels\n",
        "    \"\"\"\n",
        "\n",
        "    features = np.array([sequence[:-1] for sequence in input_sequences])\n",
        "    labels = np.array([sequence[-1] for sequence in input_sequences])\n",
        "    one_hot_labels = np.array(to_categorical(labels, num_classes = total_words))\n",
        "\n",
        "\n",
        "    return features, one_hot_labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "23DolaBRaIAZ",
        "tags": [
          "graded"
        ],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a26e981b-fbc0-476a-a88f-04d1b41f8cd6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "labels have shape: (5, 3211)\n",
            "\n",
            "features look like this:\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[  0,   0,   0,   0,   0,   0,   0,   0,   0,  34],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,  34, 417],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,  34, 417, 877],\n",
              "       [  0,   0,   0,   0,   0,   0,  34, 417, 877, 166],\n",
              "       [  0,   0,   0,   0,   0,  34, 417, 877, 166, 213]], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "# Test \n",
        "first_features, first_labels = features_and_labels(first_padded_seq, total_words)\n",
        "\n",
        "print(f\"labels have shape: {first_labels.shape}\")\n",
        "print(\"\\nfeatures look like this:\\n\")\n",
        "first_features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GRTuLEt3bRKa",
        "tags": [
          "graded"
        ],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6970db41-fb84-4781-f391-a0c1f5d9e352"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features have shape: (15462, 10)\n",
            "labels have shape: (15462, 3211)\n"
          ]
        }
      ],
      "source": [
        "# Split the whole corpus\n",
        "features, labels = features_and_labels(input_sequences, total_words)\n",
        "\n",
        "print(f\"features have shape: {features.shape}\")\n",
        "print(f\"labels have shape: {labels.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ltxaOCE_aU6J"
      },
      "source": [
        "## Create the model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "code",
        "id": "XrE6kpJFfvRY",
        "tags": [
          "graded"
        ]
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "def create_model(total_words, max_sequence_len):\n",
        "    \"\"\"\n",
        "    Creates a text generator model\n",
        "    \n",
        "    Args:\n",
        "        total_words (int): size of the vocabulary for the Embedding layer input\n",
        "        max_sequence_len (int): length of the input sequences\n",
        "    \n",
        "    Returns:\n",
        "        model (tf.keras Model): the text generator model\n",
        "    \"\"\"\n",
        "    model = Sequential()\n",
        "\n",
        "    model.add(Embedding(total_words, 100, input_length= max_sequence_len-1)),\n",
        "    model.add(Bidirectional(LSTM(150))),\n",
        "    model.add(Dense(total_words, activation='softmax'))\n",
        "\n",
        "\n",
        "    # Compile the model\n",
        "    model.compile(loss='categorical_crossentropy',\n",
        "                  optimizer='adam',\n",
        "                  metrics=['accuracy'])\n",
        "    \n",
        "\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0IpX_Gu_gISk",
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "79d71021-33a0-4191-9ea9-1c8c413d6344"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "484/484 [==============================] - 10s 7ms/step - loss: 6.8734 - accuracy: 0.0243\n",
            "Epoch 2/50\n",
            "484/484 [==============================] - 3s 7ms/step - loss: 6.4092 - accuracy: 0.0319\n",
            "Epoch 3/50\n",
            "484/484 [==============================] - 3s 7ms/step - loss: 6.1671 - accuracy: 0.0406\n",
            "Epoch 4/50\n",
            "484/484 [==============================] - 3s 7ms/step - loss: 5.9051 - accuracy: 0.0537\n",
            "Epoch 5/50\n",
            "484/484 [==============================] - 3s 7ms/step - loss: 5.6050 - accuracy: 0.0645\n",
            "Epoch 6/50\n",
            "484/484 [==============================] - 3s 7ms/step - loss: 5.2656 - accuracy: 0.0771\n",
            "Epoch 7/50\n",
            "484/484 [==============================] - 3s 7ms/step - loss: 4.8911 - accuracy: 0.0922\n",
            "Epoch 8/50\n",
            "484/484 [==============================] - 4s 8ms/step - loss: 4.4999 - accuracy: 0.1248\n",
            "Epoch 9/50\n",
            "484/484 [==============================] - 3s 7ms/step - loss: 4.1143 - accuracy: 0.1693\n",
            "Epoch 10/50\n",
            "484/484 [==============================] - 3s 7ms/step - loss: 3.7286 - accuracy: 0.2289\n",
            "Epoch 11/50\n",
            "484/484 [==============================] - 3s 7ms/step - loss: 3.3670 - accuracy: 0.2998\n",
            "Epoch 12/50\n",
            "484/484 [==============================] - 3s 7ms/step - loss: 3.0412 - accuracy: 0.3558\n",
            "Epoch 13/50\n",
            "484/484 [==============================] - 4s 9ms/step - loss: 2.7509 - accuracy: 0.4172\n",
            "Epoch 14/50\n",
            "484/484 [==============================] - 3s 7ms/step - loss: 2.4914 - accuracy: 0.4694\n",
            "Epoch 15/50\n",
            "484/484 [==============================] - 3s 7ms/step - loss: 2.2616 - accuracy: 0.5206\n",
            "Epoch 16/50\n",
            "484/484 [==============================] - 3s 7ms/step - loss: 2.0575 - accuracy: 0.5615\n",
            "Epoch 17/50\n",
            "484/484 [==============================] - 3s 7ms/step - loss: 1.8741 - accuracy: 0.6057\n",
            "Epoch 18/50\n",
            "484/484 [==============================] - 3s 7ms/step - loss: 1.7063 - accuracy: 0.6436\n",
            "Epoch 19/50\n",
            "484/484 [==============================] - 3s 7ms/step - loss: 1.5552 - accuracy: 0.6784\n",
            "Epoch 20/50\n",
            "484/484 [==============================] - 3s 7ms/step - loss: 1.4291 - accuracy: 0.7047\n",
            "Epoch 21/50\n",
            "484/484 [==============================] - 3s 7ms/step - loss: 1.3109 - accuracy: 0.7304\n",
            "Epoch 22/50\n",
            "484/484 [==============================] - 3s 7ms/step - loss: 1.2062 - accuracy: 0.7547\n",
            "Epoch 23/50\n",
            "484/484 [==============================] - 3s 7ms/step - loss: 1.1136 - accuracy: 0.7711\n",
            "Epoch 24/50\n",
            "484/484 [==============================] - 3s 7ms/step - loss: 1.0401 - accuracy: 0.7853\n",
            "Epoch 25/50\n",
            "484/484 [==============================] - 3s 7ms/step - loss: 0.9715 - accuracy: 0.7994\n",
            "Epoch 26/50\n",
            "484/484 [==============================] - 3s 7ms/step - loss: 0.9074 - accuracy: 0.8097\n",
            "Epoch 27/50\n",
            "484/484 [==============================] - 4s 7ms/step - loss: 0.8541 - accuracy: 0.8190\n",
            "Epoch 28/50\n",
            "484/484 [==============================] - 3s 7ms/step - loss: 0.8146 - accuracy: 0.8256\n",
            "Epoch 29/50\n",
            "484/484 [==============================] - 3s 7ms/step - loss: 0.7801 - accuracy: 0.8304\n",
            "Epoch 30/50\n",
            "484/484 [==============================] - 3s 7ms/step - loss: 0.7484 - accuracy: 0.8337\n",
            "Epoch 31/50\n",
            "484/484 [==============================] - 3s 7ms/step - loss: 0.7233 - accuracy: 0.8371\n",
            "Epoch 32/50\n",
            "484/484 [==============================] - 3s 7ms/step - loss: 0.7000 - accuracy: 0.8399\n",
            "Epoch 33/50\n",
            "484/484 [==============================] - 3s 7ms/step - loss: 0.6794 - accuracy: 0.8414\n",
            "Epoch 34/50\n",
            "484/484 [==============================] - 3s 7ms/step - loss: 0.6633 - accuracy: 0.8443\n",
            "Epoch 35/50\n",
            "484/484 [==============================] - 3s 7ms/step - loss: 0.6552 - accuracy: 0.8434\n",
            "Epoch 36/50\n",
            "484/484 [==============================] - 3s 7ms/step - loss: 0.6393 - accuracy: 0.8458\n",
            "Epoch 37/50\n",
            "484/484 [==============================] - 3s 7ms/step - loss: 0.6322 - accuracy: 0.8452\n",
            "Epoch 38/50\n",
            "484/484 [==============================] - 3s 7ms/step - loss: 0.6220 - accuracy: 0.8464\n",
            "Epoch 39/50\n",
            "484/484 [==============================] - 3s 7ms/step - loss: 0.6155 - accuracy: 0.8469\n",
            "Epoch 40/50\n",
            "484/484 [==============================] - 3s 7ms/step - loss: 0.6073 - accuracy: 0.8476\n",
            "Epoch 41/50\n",
            "484/484 [==============================] - 3s 7ms/step - loss: 0.5988 - accuracy: 0.8481\n",
            "Epoch 42/50\n",
            "484/484 [==============================] - 4s 7ms/step - loss: 0.6045 - accuracy: 0.8467\n",
            "Epoch 43/50\n",
            "484/484 [==============================] - 3s 7ms/step - loss: 0.5973 - accuracy: 0.8483\n",
            "Epoch 44/50\n",
            "484/484 [==============================] - 3s 7ms/step - loss: 0.5865 - accuracy: 0.8494\n",
            "Epoch 45/50\n",
            "484/484 [==============================] - 3s 7ms/step - loss: 0.5768 - accuracy: 0.8491\n",
            "Epoch 46/50\n",
            "484/484 [==============================] - 3s 7ms/step - loss: 0.5765 - accuracy: 0.8478\n",
            "Epoch 47/50\n",
            "484/484 [==============================] - 3s 7ms/step - loss: 0.5708 - accuracy: 0.8490\n",
            "Epoch 48/50\n",
            "484/484 [==============================] - 3s 7ms/step - loss: 0.5705 - accuracy: 0.8490\n",
            "Epoch 49/50\n",
            "484/484 [==============================] - 3s 7ms/step - loss: 0.5705 - accuracy: 0.8495\n",
            "Epoch 50/50\n",
            "484/484 [==============================] - 3s 7ms/step - loss: 0.5694 - accuracy: 0.8483\n"
          ]
        }
      ],
      "source": [
        "# Get the untrained model\n",
        "model = create_model(total_words, max_sequence_len)\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(features, labels, epochs=50, verbose=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1fXTEO3GJ282",
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 545
        },
        "outputId": "fb628d16-eb3d-4e67-ea3f-e0a3f0870ab4"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWoAAAEICAYAAAB25L6yAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3deXxU1f3/8deHJCRAWBSCyiZQLIogQeKuNdjqF8W1LlVBS20f4IpaLQpuoFC0VXEB6lKptiqu1bpVRYri0h8acEEK2qog4MKirLKGz++PM5GAgUySmdxZ3s/H4z7mzp17J59bxvecnjn3XHN3REQkdTWIugAREdkxBbWISIpTUIuIpDgFtYhIilNQi4ikOAW1iEiKU1BLyjOzf5rZLxO9bw1rKDWzhYl+X5F45EZdgGQmM1td6WljYD1QHns+2N0five93P3oZOwrki4U1JIU7l5YsW5m84DfuPsr2+5nZrnuvqk+axNJN+r6kHpV0YVgZleY2VfAX8xsJzN7zsyWmNm3sfV2lY551cx+E1sfaGZvmNnNsX0/M7Oja7lvJzObZmarzOwVMxtvZg/GeR57xf7WcjObbWbHV3rtGDP7T+x9F5nZ5bHtrWLnttzMvjGz181M/w1KtfQhkSjsCuwM7A4MInwO/xJ73gFYC4zbwfEHAB8BrYA/APeZmdVi34eBt4GWwAjgrHiKN7M84FngZaA1cBHwkJl1je1yH6F7pynQHfhXbPtlwEKgCNgFGA5oDgeploJaorAZuM7d17v7Wndf5u5Puvt37r4KGA0cvoPj57v7ve5eDjwA7EYIvrj3NbMOwH7Ate6+wd3fAJ6Js/4DgULgxtix/wKeA86Ivb4R6GZmzdz9W3efWWn7bsDu7r7R3V93TbYjcVBQSxSWuPu6iidm1tjM7jaz+Wa2EpgGtDCznO0c/1XFirt/F1strOG+bYBvKm0DWBBn/W2ABe6+udK2+UDb2PrJwDHAfDN7zcwOim3/I/A/4GUz+9TMrozz70mWU1BLFLZtRV4GdAUOcPdmwE9i27fXnZEIXwI7m1njStvax3nsF0D7bfqXOwCLANz9HXc/gdAt8jTwWGz7Kne/zN07A8cDvzWzn9bxPCQLKKglFTQl9EsvN7OdgeuS/QfdfT5QBowws4axVu9xcR4+HfgOGGpmeWZWGjv2kdh79Tez5u6+EVhJ6OrBzI41sy6xPvIVhOGKm6v+EyJbKKglFdwGNAKWAv8PeLGe/m5/4CBgGTAKeJQw3nuH3H0DIZiPJtQ8ATjb3efGdjkLmBfrxjk39ncA9gBeAVYD/wYmuPvUhJ2NZCzTbxkigZk9Csx196S36EVqQi1qyVpmtp+Z/cjMGphZX+AEQp+ySErRlYmSzXYF/k4YR70QOM/d3422JJEfUteHiEiKU9eHiEiKS0rXR6tWrbxjx47JeGsRkYw0Y8aMpe5eVNVrSQnqjh07UlZWloy3FhHJSGY2f3uvqetDRCTFVRvUZtbVzN6rtKw0s0vqozgREYmj68PdPwKKAWKT5CwCnkpyXSIiElPTPuqfAp/E5kkQkTSxceNGFi5cyLp166rfWZKqoKCAdu3akZeXF/cxNQ3q04FJVb1gZoMIk8DToUOHGr6tiCTTwoULadq0KR07dmT791iQZHN3li1bxsKFC+nUqVPcx8X9Y6KZNSRMzfj4dgq4x91L3L2kqKjKESYiEpF169bRsmVLhXTEzIyWLVvW+P/Z1GTUx9HATHf/ukZ/QURSgkI6NdTm36EmQX0G2+n2SIS1a+GWW+DVV5P1F0RE0lNcQW1mTYAjCRPYJEVubgjqG29M1l8QkagsW7aM4uJiiouL2XXXXWnbtu33zzds2LDDY8vKyhgyZEi1f+Pggw9OSK2vvvoqxx57bELeK1Hi+jHR3dcQZhhLmrw8OO88uPZa+Ogj6Nq1+mNEJD20bNmS9957D4ARI0ZQWFjI5Zdf/v3rmzZtIje36jgqKSmhpKSk2r/x1ltvJabYFJRSVyYOGgQNG8L48VFXIiLJNnDgQM4991wOOOAAhg4dyttvv81BBx1Er169OPjgg/noo4+ArVu4I0aM4JxzzqG0tJTOnTtzxx13fP9+hYWF3+9fWlrKKaecwp577kn//v2pmCX0hRdeYM8996R3794MGTKkRi3nSZMm0aNHD7p3784VV1wBQHl5OQMHDqR79+706NGDsWPHAnDHHXfQrVs39tlnH04//fQ6/2+VUvNR77ILnHYa3H8/jBoFzZpFXZFI5rnkEog1bhOmuBhuu63mxy1cuJC33nqLnJwcVq5cyeuvv05ubi6vvPIKw4cP58knn/zBMXPnzmXq1KmsWrWKrl27ct555/1gTPK7777L7NmzadOmDYcccghvvvkmJSUlDB48mGnTptGpUyfOOOOMuOv84osvuOKKK5gxYwY77bQTRx11FE8//TTt27dn0aJFfPjhhwAsX74cgBtvvJHPPvuM/Pz877fVRUq1qAGGDIFVq+CBB6KuRESS7dRTTyUnJweAFStWcOqpp9K9e3cuvfRSZs+eXeUx/fr1Iz8/n1atWtG6dWu+/vqHA9H2339/2rVrR4MGDSguLmbevHnMnTuXzp07fz9+uSZB/c4771BaWkpRURG5ubn079+fadOm0blzZz799FMuuugiXnzxRZrFWpf77LMP/fv358EHH9xul05NpFSLGmC//eCAA2DcOLjgAmiQcl8lIumtNi3fZGnSpMn369dccw19+vThqaeeYt68eZSWllZ5TH5+/vfrOTk5bNq0qVb7JMJOO+3E+++/z0svvcRdd93FY489xsSJE3n++eeZNm0azz77LKNHj2bWrFl1CuyUjMGLLoKPP4bJk6OuRETqy4oVK2jbti0A999/f8Lfv2vXrnz66afMmzcPgEcffTTuY/fff39ee+01li5dSnl5OZMmTeLwww9n6dKlbN68mZNPPplRo0Yxc+ZMNm/ezIIFC+jTpw833XQTK1asYPXq1XWqPSWD+tRTQ3/1nXdGXYmI1JehQ4cybNgwevXqlZQWcKNGjZgwYQJ9+/ald+/eNG3alObNm1e575QpU2jXrt33y7x587jxxhvp06cPPXv2pHfv3pxwwgksWrSI0tJSiouLGTBgAGPGjKG8vJwBAwbQo0cPevXqxZAhQ2jRokWdak/KPRNLSkq8rjcOGDECrr8+tKy7dElMXSLZas6cOey1115RlxG51atXU1hYiLtzwQUXsMcee3DppZfWex1V/XuY2Qx3r3IcYkq2qAEGD4acHA3VE5HEuffeeykuLmbvvfdmxYoVDB48OOqS4pKyLWqAM8+E55+HRYsgNkRSRGpBLerUkjEtagg/Kq5cCX/7W9SViKS/ZDTKpOZq8++Q0kF94IFQUhJ+VNRnTKT2CgoKWLZsmcI6YhXzURcUFNTouJQbR12ZWWhV//KXMGUK/OxnUVckkp7atWvHwoULWbJkSdSlZL2KO7zUREr3UQOsXw/t20O3biGsYxcxiYhklLTtowbIz4cxY+C11yA2D4qISFZJ6a6PCr/+Nbz7bpivep994Oyzo65IRKT+pHyLusLYsdCnT5gKdfr0qKsREak/aRPUeXnw+OPQpg2cdFIYWy0ikg3SJqgBWraEZ54J06CedFK4z6KISKZLq6AG6N4dHnwQ3nkndINoWKiIZLq0C2qAE04IEzY9+CDcfHPU1YiIJFdaBjXA1VeH6VCvvBKmTo26GhGR5EnboDaD++6DPfYIkzd99VXUFYmIJEdcQW1mLczsCTOba2ZzzOygZBcWj6ZNw0iQFStCWJeXR12RiEjixduivh140d33BHoCc5JXUs306AETJoTuj5Ejo65GRCTxqg1qM2sO/AS4D8DdN7h73e9/nkADB4Zl1Ch4+eWoqxERSax4WtSdgCXAX8zsXTP7s5k1qe6g+jZ+POy9N/Tvr4thRCSzxBPUucC+wJ/cvRewBrhy253MbJCZlZlZWRRTKTZuHPqr166F00+HJN0dXkSk3sUT1AuBhe5eMcPGE4Tg3oq73+PuJe5eUlRUlMga47bnnnDPPfDGG2H4nohIJqg2qN39K2CBmXWNbfop8J+kVlUHZ54Zbox7001h/moRkXQX76iPi4CHzOwDoBj4ffJKqruxY+HHP4bf/AZWr466GhGRuokrqN39vVi3xj7ufqK7f5vswuqiUSOYOBHmz4dhw6KuRkSkbtL2ysTqHHIIDBkC48bBtGlRVyMiUnsZG9QAo0dD585wzjnw3XdRVyMiUjsZHdRNmoT5QD75RKNARCR9ZXRQA5SWwvnnw223wZtvRl2NiEjNZXxQA9x4I3ToELpAdFcYEUk3WRHUTZvCvffCxx/DdddFXY2ISM1kRVADHHlkGFd9yy3hNl4iIukia4Iawm27WreGCy+EzZujrkZEJD5ZFdTNm4dLy99+G/7616irERGJT1YFNcCAAXDggeFeiytXRl2NiEj1si6oGzSAO+6Ar7+GG26IuhoRkeplXVAD7Lcf/OpXcPvtYSSIiEgqy8qgBhgzJkzedOmlUVciIrJjWRvUu+wC114LL7wAzz8fdTUiItuXtUENcNFF0LVraFWvXx91NSIiVcvqoG7YMMwB8t//hv5qEZFUlNVBDdC3Lxx3XBgB8uWXUVcjIvJDWR/UALfeChs2wFVXRV2JiMgPKaiBLl3gggvggQdgzpyoqxER2ZqCOmbYMGjcGK65JupKRES2pqCOKSqCyy6DJ5/U7HoikloU1JX89rfQqhUMHx51JSIiWyioK2nWLIT0K6/AlClRVyMiEsQV1GY2z8xmmdl7ZlaW7KKidN550L59CGz3qKsREalZi7qPuxe7e0nSqkkBBQUwYkSYs/rpp6OuRkREXR9VOvts2HPPMK66vDzqakQk28Ub1A68bGYzzGxQVTuY2SAzKzOzsiVLliSuwgjk5sKoUWFM9d/+FnU1IpLtzOPoiDWztu6+yMxaA5OBi9x92vb2Lykp8bKy9O7Kdof994fFi8Oc1fn5UVckIpnMzGZsr2s5rha1uy+KPS4GngL2T1x5qckMfv97+PxzuPvuqKsRkWxWbVCbWRMza1qxDhwFfJjswlLBz34GRxwBo0fDmjVRVyMi2SqeFvUuwBtm9j7wNvC8u7+Y3LJSgxlcf33o/pgwIepqRCRbxdVHXVOZ0EddWd++MGMGfPYZFBZGXY2IZKI691Fnu5EjYelSGDcu6kpEJBspqONwwAFwzDHwxz/CypVRVyMi2UZBHaeRI+Gbb+DOO6OuRESyjYI6TiUl4ZZdN98MK1ZEXY2IZBMFdQ2MHAnLl4cb4oqI1BcFdQ306gUnnghjx8K330ZdjYhkCwV1DY0YEbo+xo6NuhIRyRYK6hrq2RNOOSV0f3zzTdTViEg2UFDXwnXXwerVcMstUVciItlAQV0L3bvDaafB7bdDms/oKiJpQEFdS9ddB2vXwh/+EHUlIpLpFNS1tNde0L8/jB8PX34ZdTUikskU1HVw7bWwYQOMGRN1JSKSyRTUddClC/zqV+HGAgsWRF2NiGQqBXUdXX11uG3XqFFRVyIimUpBXUe77w6DBsHEifDpp1FXIyKZSEGdAMOHhzuXX3991JWISCZSUCdAmzZw/vnwt7/BRx9FXY2IZBoFdYJccQU0ahTmAhERSSQFdYK0bg1DhsAjj8CsWVFXIyKZREGdQJdfDs2ahasWRUQSRUGdQDvvDL/9LTz1VLhruYhIIsQd1GaWY2bvmtlzySwo3V1yCey0U7hqUUQkEWrSor4YmJOsQjJF8+YwdCi88AL8+99RVyMimSCuoDazdkA/4M/JLSczXHghFBXBNddEXYmIZIJ4W9S3AUOBzdvbwcwGmVmZmZUtyfJJmgsLYdgwmDIFXn016mpEJN1VG9Rmdiyw2N13+POYu9/j7iXuXlJUVJSwAtPVueeGC2GuuSbMBSIiUlvxtKgPAY43s3nAI8ARZvZgUqvKAI0awVVXwRtvwOTJUVcjIunMvAbNPTMrBS5392N3tF9JSYmXlZXVsbT0t349/PjHsMsuMH06mEVdkYikKjOb4e4lVb2mcdRJlJ8fhum98w48p0GNIlJLNWpRx0st6i02boRu3aBJE5g5Exroq1FEqqAWdYTy8sIl5e+/D3//e9TViEg6UlDXgzPOCDfDvfZaKC+PuhoRSTcK6nqQkwMjR8KcOfDww1FXIyLpRkFdT04+GfbdN4yrXrcu6mpEJJ0oqOtJgwbwxz/C/PkwblzU1YhIOlFQ16MjjoCjj4bRo+Gbb6KuRkTShYK6nt10E6xYAb//fdSViEi6UFDXsx49YOBAuPNO+OyzqKsRkXSgoI7A9deHkSBXXx11JSKSDhTUEWjXDi69NAzV0y27RKQ6CuqIDB0KrVrB736naVBFZMcU1BFp3jxcqTh1Kvzzn1FXIyKpTEEdocGDoUuX0LrWpeUisj0K6gg1bAhjxsDs2XD//VFXIyKpSkEdsZNPhoMOguHD4dtvo65GRFKRgjpiZjB+PCxdquF6IlI1BXUK6NULLrgA/vQnDdcTkR9SUKeIG26A1q3hvPP0w6KIbE1BnSKaN4dbbgn3V/zzn6OuRkRSiYI6hZx5JpSWwrBhsHhx1NWISKpQUKcQM5gwAVatgiuuiLoaEUkVCuoUs9decNllYVz1G29EXY2IpAIFdQq65hpo3x7OPx82bYq6GhGJWrVBbWYFZva2mb1vZrPNbGR9FJbNmjSB22+HWbPCvNUikt3iaVGvB45w955AMdDXzA5Mblly4olwzDHhIphPPom6GhGJUrVB7cHq2NO82KKJOZPMDO66C/Lywh1hNLZaJHvF1UdtZjlm9h6wGJjs7tOr2GeQmZWZWdmSJUsSXWdWat8e7rgj/Kg4dmzU1YhIVOIKancvd/dioB2wv5l1r2Kfe9y9xN1LioqKEl1n1jrrrNANctVVYZY9Eck+NRr14e7LgalA3+SUI9syg7vvDlcunn02bNwYdUUiUt/iGfVRZGYtYuuNgCOBuckuTLZo3Tr0V8+cCaNGRV2NiNS3eFrUuwFTzewD4B1CH/VzyS1LtvXzn8OAATB6dJgPRESyh3kS7qxaUlLiZWVlCX/fbLd8OXTvDs2ahelQGzWKuiIRSRQzm+HuJVW9pisT00iLFjBxIsyZo5sMiGQTBXWaOeqoMGf12LHw4otRVyMi9UFBnYZuvjl0gQwYAAsWRF2NiCSbgjoNNW4Mjz8O69fDL34BGzZEXZGIJJOCOk117Qr33Qf//rfmrhbJdArqNHbaaXDRRXDbbfDkk1FXIyLJoqBOczffDAccAOecA//9b9TViEgyKKjTXMOG8NhjkJsLp5wCa9dGXZGIJJqCOgN06AAPPggffBC6QkQksyioM8TRR4cZ9u67L8wLIiKZQ0GdQUaOhH794MILdTGMSCZRUGeQnBx45BHo0QNOPRXefz/qikQkERTUGaawEJ57Lsxf3a8fLFoUdUUiUlcK6gzUti08/zysWAHHHgurV1d/jIikLgV1hurZMwzbmzULTj8dNm2KuiIRqS0FdQY7+mgYNy60ri+5BJIw9biI1IPcqAuQ5Dr3XPjkk3AFY/v2mhdEJB0pqLPATTfBwoVw5ZXhrjBDhkRdkYjUhII6CzRoAH/9a5gW9eKLIT8fBg+OuioRiZf6qLNEXl4YY92vX+gOeeCBqCsSkXgpqLNIw4bwxBNw5JFhtr1Jk6KuSETioaDOMgUF8PTT8JOfwFlnaR5rkXRQbVCbWXszm2pm/zGz2WZ2cX0UJsnTuDE8+2yYx/r00+GZZ6KuSER2JJ4W9SbgMnfvBhwIXGBm3ZJbliRbYSG88ALsuy+cfDI89FDUFYnI9lQb1O7+pbvPjK2vAuYAbZNdmCRf8+bwyitw2GHhjubjxkVdkYhUpUZ91GbWEegFTK/itUFmVmZmZUuWLElMdZJ0TZuGlvWJJ4abDowcqSsYRVJN3EFtZoXAk8Al7r5y29fd/R53L3H3kqKiokTWKElWUACPPw4DB8KIEWGs9ebNUVclIhXiuuDFzPIIIf2Qu/89uSVJFHJzw91hdt4Zbr0Vvv0WJk4M469FJFrVBrWZGXAfMMfdb01+SRKVBg3CnCCtWsHw4fDNN/Doo+GHRxGJTjxdH4cAZwFHmNl7seWYJNclETGDYcPg7rvhpZfg0ENhwYKoqxLJbtW2qN39DcDqoRZJIYMGwe67w2mnhfHWzzwDJSVRVyWSnXRlomzX//0fvPVWmMTpJz/RVYwiUVFQyw7tvTdMnw7FxXDKKTBmjIbvidQ3BbVUq3Vr+Ne/4Iwzwo+M55wD69ZFXZVI9lBQS1wKCsJl5tddB/ffD4ccAp9+GnVVItlBQS1xMwsXxPzjHyGk9903rItIcimopcaOPx5mzoQuXcKl57/7HWzcGHVVIplLQS210qkTvPkmnH9+uEjmiCNg0aKoqxLJTApqqbX8fBg/PvRdv/su9OoVbkogIomloJY6O/NMeOcdaNMGTjoJfv5z+OKLqKsSyRwKakmIvfYKYT1mDPzzn+H5XXdpFj6RRFBQS8Lk5cGVV8KsWeFy8/POg8MPhzlzoq5MJL0pqCXhunQJd46ZOBFmzw5XNV57LXz3XdSViaQnBbUkhRn86lehNX3KKXDDDdCtW/ixUZegi9SMglqSapddwqiQqVPDvNYnnQTHHAMffxx1ZSLpQ0Et9aK0NAzhGzs2zMjXo0eYN2TNmqgrE0l9CmqpN3l5cMkl8NFH8ItfhBEie+wRblKgKxtFtk9BLfVu113hr3+FN96Azp3h3HND//WkSRrOJ1IVBbVE5pBD4PXX4bnnoHHjcOHMvvvCCy/oB0eRyhTUEikz6Ncv9F8/9BCsWhWeH3aYAlukgoJaUkKDBqFFPXcuTJgAn38eArtnT3j4Ydi0KeoKRaKjoJaUkpcXrmj85BN44AEoL4f+/cOPjuPH66IZyU4KaklJeXlw9tnhcvRnngkTPl14Ybgz+qWXwnvvRV2hSP2pNqjNbKKZLTazD+ujIJHKGjSA444Lc1+//nqYO2TChDClas+ecOut8PXXUVcpklzxtKjvB/omuQ6Rah16KDzxBHz5ZegGKSiAyy6Dtm3h2GPD8D5dQCOZqNqgdvdpwDf1UItIXHbeOdxZZvp0+M9/wq3A3n8//BjZunW4W/o//gHr10ddqUhiJKyP2swGmVmZmZUtWbIkUW8rskN77RWucJw/H157LfRrT54c7uW4667w61/DSy/Bhg1RVypSe+ZxDFQ1s47Ac+7ePZ43LSkp8bKysrpVJlJLGzfClCmhK+Spp8LY7BYtQl/3ySfDUUdBo0ZRVymyNTOb4e4lVb2mUR+ScfLyoG/fMLxv8eIwauSEE8IVkCeeCEVFYa6Rhx8Or4ukutyoCxBJpoKC0JI+7rjQ0p46FZ58MsyL/dhjYZ+ePeHII8Ny2GFqbUvqqbbrw8wmAaVAK+Br4Dp3v29Hx6jrQ1JdeTnMmBH6sydPDlOvbtwY7qx+0EGw337Qu3e4pVjnzuFSd5Fk2lHXR1x91DWloJZ0s2YNTJsWQnvaNPjggy1Tr7ZoESaL6t0b9tkHuncPP2Lm50dbs2QWBbVIDW3YAB9+GFrdFcsHH2wZPZKTEy5r79EjBHe3biG899gDGjaMtnZJTwpqkQTYuBH+979wWfuHH255/OSTLbP85eTAj34UQrsiuDt1go4doX17yNWvQrIdOwpqfWxE4pSXtyWATztty/bvvgt3rZkzJ1yAM2dOWJ5/futZ/3JyoF27ENy77x6WDh22LO3bh3m5RbaloBapo8aNw9wjvXptvX3jRliwAObNg88+2/rxlVfCpfDb3tGmZctwSXybNj98bN06DC0sKgo3CtYPnNlDQS2SJHl5YcRI585Vv75xI3zxRZh7+/PPw9WVCxaEbYsWhcviv/qq6psn5OeHwG7VCpo1gyZNwhdG5cfmzcPrFeFesb7TTqE2SR8KapGI5OVt6QLZnk2bwuyAixbBkiVblqVLt6yvWhWer1kTumHWrNmyvj05OWG8eMXSuHFYCgtD8DdtGpaK9Yr9Cgq2PBYU/PDLofJjA11OlzAKapEUlpsbuj7atq35sRs2wLJlWwf70qXw7bewdm1Yvvtu6/VVq8KXwqpVYVm5MrxWG40ahdCuvDRsGCbLWrdu68cNG7Z8CVR8cVQ8VnxhbLtUfJkUFm79mJ+/dbdQxXqDBuG1hg3Tr9tIQS2SoRo2hN12C0tdlJeHsF63buvHiqWi9V7Rmq/cql+zBlav3rK+YUMI2YKCEJoVj3l5IbArf3GsXRu+VD7/PHxhrFwZvjwSIT9/y99v2HBL678iwLd9rIpZOK7yY1FRGIefaApqEdmhnJzQWi0sjLqS8OPr6tVbQnv16h8+rlu3Zf/K/fvl5eHLoGKpaM2vXx/2q9h328eqVOzvHmqqeGzePPHnDApqEUkjDRps6frIJuruFxFJcQpqEZEUp6AWEUlxCmoRkRSnoBYRSXEKahGRFKegFhFJcQpqEZEUl5QbB5jZEmB+LQ9vBSxNYDnpQuedXXTe2SWe897d3YuqeiEpQV0XZla2vbscZDKdd3bReWeXup63uj5ERFKcglpEJMWlYlDfE3UBEdF5Zxedd3ap03mnXB+1iIhsLRVb1CIiUomCWkQkxaVMUJtZXzP7yMz+Z2ZXRl1PMpnZRDNbbGYfVtq2s5lNNrP/xh53irLGRDOz9mY21cz+Y2azzezi2PaMPm8AMysws7fN7P3YuY+Mbe9kZtNjn/lHzaxh1LUmmpnlmNm7ZvZc7HnGnzOAmc0zs1lm9p6ZlcW21fqznhJBbWY5wHjgaKAbcIaZdYu2qqS6H+i7zbYrgSnuvgcwJfY8k2wCLnP3bsCBwAWxf+NMP2+A9cAR7t4TKAb6mtmBwE3AWHfvAnwL/DrCGpPlYmBOpefZcM4V+rh7caXx07X+rKdEUAP7A/9z90/dfQPwCHBCxDUljbtPA77ZZvMJwAOx9QeAE+u1qCRz9y/dfWZsfRXhP962ZPh5A3iwOvY0L7Y4cATwRGx7xp27mbUD+gF/jj03Mvycq1Hrz3qqBHVbYEGl5wtj27LJLu7+ZWgEwSQAAAH0SURBVGz9K2CXKItJJjPrCPQCppMl5x3rAngPWAxMBj4Blrv7ptgumfiZvw0YCmyOPW9J5p9zBQdeNrMZZjYotq3Wn3Xd3DYFububWUaOmzSzQuBJ4BJ3XxkaWUEmn7e7lwPFZtYCeArYM+KSksrMjgUWu/sMMyuNup4IHOrui8ysNTDZzOZWfrGmn/VUaVEvAtpXet4uti2bfG1muwHEHhdHXE/CmVkeIaQfcve/xzZn/HlX5u7LganAQUALM6toLGXaZ/4Q4Hgzm0foyjwCuJ3MPufvufui2ONiwhfz/tThs54qQf0OsEfsF+GGwOnAMxHXVN+eAX4ZW/8l8I8Ia0m4WP/kfcAcd7+10ksZfd4AZlYUa0ljZo2AIwl99FOBU2K7ZdS5u/swd2/n7h0J/z3/y937k8HnXMHMmphZ04p14CjgQ+rwWU+ZKxPN7BhCn1YOMNHdR0dcUtKY2SSglDD14dfAdcDTwGNAB8IUsae5+7Y/OKYtMzsUeB2YxZY+y+GEfuqMPW8AM9uH8ONRDqFx9Ji7X29mnQmtzZ2Bd4EB7r4+ukqTI9b1cbm7H5sN5xw7x6diT3OBh919tJm1pJaf9ZQJahERqVqqdH2IiMh2KKhFRFKcglpEJMUpqEVEUpyCWkQkxSmoRURSnIJaRCTF/X+iAKRV+oMFegAAAABJRU5ErkJggg==\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "# Take a look at the training curves of model\n",
        "\n",
        "acc = history.history['accuracy']\n",
        "loss = history.history['loss']\n",
        "\n",
        "epochs = range(len(acc))\n",
        "\n",
        "plt.plot(epochs, acc, 'b', label='Training accuracy')\n",
        "plt.title('Training accuracy')\n",
        "\n",
        "plt.figure()\n",
        "\n",
        "plt.plot(epochs, loss, 'b', label='Training Loss')\n",
        "plt.title('Training loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wdsMszk9zBs_"
      },
      "source": [
        "## See the model in action\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6Vc6PHgxa6Hm",
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "36e2c1f7-0098-43c7-e027-8908f6041738"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Love yourself a little more slave of white too red much image image shine ' of wardrobe glass do under my state oppress'd nor heart quite growest gone of my brain that fire and found doth heart alone graves one near name in thine eyes be more more can thy strength are new ' ' ' back so bright my love still still did still ' ' say with store in thee in my side reign'd truth and seen weeds night night fierce face both date entombed reigns truth and loss of store in thee words still doth too rage must hence hence remain now\n"
          ]
        }
      ],
      "source": [
        "seed_text = \"Love yourself a little more\"\n",
        "next_words = 100\n",
        "  \n",
        "for _ in range(next_words):\n",
        "\t# Convert the text into sequences\n",
        "\ttoken_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
        "\t# Pad the sequences\n",
        "\ttoken_list = pad_sequences([token_list], maxlen=max_sequence_len-1, padding='pre')\n",
        "\t# Get the probabilities of predicting a word\n",
        "\tpredicted = model.predict(token_list, verbose=0)\n",
        "\t# Choose the next word based on the maximum probability\n",
        "\tpredicted = np.argmax(predicted, axis=-1).item()\n",
        "\t# Get the actual word from the word index\n",
        "\toutput_word = tokenizer.index_word[predicted]\n",
        "\t# Append to the current text\n",
        "\tseed_text += \" \" + output_word\n",
        "\n",
        "print(seed_text)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
      ],
      "metadata": {
        "id": "VuhD5v2VZhtK"
      }
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "dlai_version": "1.2.0",
    "jupytext": {
      "main_language": "python"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
